{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import bsg, tools\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "princeton_data = pd.read_csv(\"articles_1999.csv\", delimiter=\"\\|\\~\\|\", header=None)\n",
    "princeton_data.columns = [\"ID\", \"headline\", \"date\", \"type\", \"author\", \"author_title\", \"article\", \"author_bio\"]\n",
    "princeton_data = princeton_data[princeton_data[\"article\"].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prince_data = list(princeton_data.loc[0:40,\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prince_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Stuff ###\n",
    "\n",
    "window = 2\n",
    "t = np.power(10.0,-4.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, tokenized_corpus, word2idx, idx2word = tools.tokenize_corpus(prince_data)\n",
    "\n",
    "indexed_corpus = tools.index_tokenized_corpus(tokenized_corpus, word2idx)\n",
    "\n",
    "flattened_indexed_corpus = tools.flatten(indexed_corpus)\n",
    "unigram_subsampling = tools.make_unigram_dict(flattened_indexed_corpus)\n",
    "\n",
    "subsampled_indexed_corpus = tools.subsample_corpus(indexed_corpus, unigram_subsampling, t)\n",
    "\n",
    "sum([len(doc) for doc in subsampled_indexed_corpus])\n",
    "\n",
    "len(flattened_indexed_corpus)\n",
    "\n",
    "corpus_center_words, corpus_context_words = tools.get_corpus_centers_contexts(subsampled_indexed_corpus, window)\n",
    "\n",
    "unigram = tools.make_unigram_dict(corpus_center_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12784])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_center_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## w2v ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_prince = list(princeton_data.loc[0:princeton_data.shape[0],6])\n",
    "# vocabulary, tokenized_corpus, word2idx, idx2word = tools.tokenize_corpus(princeton_data[\"article\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540690, 954250)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### word2vec ###\n",
    "\n",
    "w2v = Word2Vec(sample = t, sg=1, negative=1, size=30, window=2, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "\n",
    "w2v.build_vocab(tokenized_corpus)  # prepare the model vocabulary\n",
    "w2v.train(tokenized_corpus, total_examples=w2v.corpus_count, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"barbara\" in w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stereotype', 0.6241565942764282),\n",
       " ('premier', 0.6206339597702026),\n",
       " ('papers', 0.6167088150978088),\n",
       " ('date', 0.5841314792633057),\n",
       " ('humans', 0.5464102029800415),\n",
       " ('town', 0.5446085333824158),\n",
       " ('vulnerability', 0.5382357835769653),\n",
       " ('cartoons', 0.5376099348068237),\n",
       " ('extension', 0.5208137035369873),\n",
       " ('eligible', 0.5180891752243042)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(\"jewish\") # assault, financial, mental, income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get corpus: 20 news groups\n",
    "\n",
    "# newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# window = 5\n",
    "\n",
    "# vocabulary, tokenized_corpus, word2idx, idx2word = tools.tokenize_corpus(newsgroups_train.data)\n",
    "\n",
    "# indexed_corpus = tools.index_tokenized_corpus(tokenized_corpus, word2idx)\n",
    "\n",
    "# corpus_center_words, corpus_context_words = tools.get_corpus_centers_contexts(indexed_corpus, window)\n",
    "\n",
    "# unigram = tools.make_unigram_dict(corpus_center_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\"vocab_size\" : len(vocabulary), \"window\" : window, \n",
    "             \"batch_size\" : 200, \"optimizer\" : 80, \"learning_rate\" : 0.0005, \n",
    "             \"momentum\" : 0.99, \"num_epoch\" : 50, \"init_mult\" : 1, \n",
    "             \"variance\" : 0.995, \"start\" : True, \"nogpu\" : True, \n",
    "             \"embedding_dim\" : 300, \"freeze\" : False}\n",
    "\n",
    "args = SimpleNamespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=50344.76953125\n",
      "Epoch 5, loss=26069.400390625\n",
      "Epoch 10, loss=16207.2314453125\n",
      "Epoch 15, loss=10887.6474609375\n",
      "Epoch 20, loss=7951.52392578125\n",
      "Epoch 25, loss=5915.08544921875\n",
      "Epoch 30, loss=4590.451171875\n",
      "Epoch 35, loss=3569.544677734375\n",
      "Epoch 40, loss=2941.241455078125\n",
      "Epoch 45, loss=2436.4189453125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = bsg.BSG(args.window, unigram, args.vocab_size, input_dim = 50, latent_dim = 30)\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "model = bsg.train(model, args, optimizer, corpus_center_words, corpus_context_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Profile printout saved to text file 'lprofencoder'. \n"
     ]
    }
   ],
   "source": [
    "# %lprun -T lprofencoder -f bsg.BSG.encoder model.encoder(corpus_center_words[0:2], corpus_context_words[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder(corpus_center_words[0:2], corpus_context_words[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"bsg_prince_latent30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"bsg_prince_latent30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx2word.get(corpus_center_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "types, counts = np.unique(corpus_center_words.tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx2realidx = {idx: realidx for (idx , realidx) in enumerate(types)}\n",
    "test_realidx2idx = {realidx: idx for (idx , realidx) in enumerate(types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2,\n",
       " 1: 4,\n",
       " 2: 5,\n",
       " 3: 6,\n",
       " 4: 10,\n",
       " 5: 16,\n",
       " 6: 20,\n",
       " 7: 21,\n",
       " 8: 30,\n",
       " 9: 33,\n",
       " 10: 36,\n",
       " 11: 42,\n",
       " 12: 43,\n",
       " 13: 46,\n",
       " 14: 47,\n",
       " 15: 48,\n",
       " 16: 52,\n",
       " 17: 53,\n",
       " 18: 54,\n",
       " 19: 65,\n",
       " 20: 68,\n",
       " 21: 73,\n",
       " 22: 75,\n",
       " 23: 76,\n",
       " 24: 79,\n",
       " 25: 88,\n",
       " 26: 90,\n",
       " 27: 92,\n",
       " 28: 93,\n",
       " 29: 105,\n",
       " 30: 109,\n",
       " 31: 113,\n",
       " 32: 118,\n",
       " 33: 119,\n",
       " 34: 126,\n",
       " 35: 127,\n",
       " 36: 130,\n",
       " 37: 137,\n",
       " 38: 150,\n",
       " 39: 166,\n",
       " 40: 167,\n",
       " 41: 168,\n",
       " 42: 172,\n",
       " 43: 173,\n",
       " 44: 178,\n",
       " 45: 180,\n",
       " 46: 181,\n",
       " 47: 187,\n",
       " 48: 189,\n",
       " 49: 190,\n",
       " 50: 191,\n",
       " 51: 194,\n",
       " 52: 196,\n",
       " 53: 203,\n",
       " 54: 205,\n",
       " 55: 206,\n",
       " 56: 207,\n",
       " 57: 220,\n",
       " 58: 229,\n",
       " 59: 233,\n",
       " 60: 235,\n",
       " 61: 236,\n",
       " 62: 238,\n",
       " 63: 239,\n",
       " 64: 240,\n",
       " 65: 241,\n",
       " 66: 242,\n",
       " 67: 245,\n",
       " 68: 246,\n",
       " 69: 254,\n",
       " 70: 255,\n",
       " 71: 257,\n",
       " 72: 260,\n",
       " 73: 261,\n",
       " 74: 266,\n",
       " 75: 268,\n",
       " 76: 269,\n",
       " 77: 270,\n",
       " 78: 274,\n",
       " 79: 275,\n",
       " 80: 280,\n",
       " 81: 281,\n",
       " 82: 288,\n",
       " 83: 293,\n",
       " 84: 296,\n",
       " 85: 310,\n",
       " 86: 319,\n",
       " 87: 322,\n",
       " 88: 324,\n",
       " 89: 326,\n",
       " 90: 328,\n",
       " 91: 334,\n",
       " 92: 335,\n",
       " 93: 336,\n",
       " 94: 339,\n",
       " 95: 343,\n",
       " 96: 349,\n",
       " 97: 352,\n",
       " 98: 354,\n",
       " 99: 355,\n",
       " 100: 357,\n",
       " 101: 358,\n",
       " 102: 361,\n",
       " 103: 363,\n",
       " 104: 368,\n",
       " 105: 369,\n",
       " 106: 371,\n",
       " 107: 373,\n",
       " 108: 377,\n",
       " 109: 380,\n",
       " 110: 382,\n",
       " 111: 384,\n",
       " 112: 386,\n",
       " 113: 390,\n",
       " 114: 394,\n",
       " 115: 396,\n",
       " 116: 397,\n",
       " 117: 410,\n",
       " 118: 411,\n",
       " 119: 416,\n",
       " 120: 418,\n",
       " 121: 422,\n",
       " 122: 426,\n",
       " 123: 439,\n",
       " 124: 441,\n",
       " 125: 450,\n",
       " 126: 459,\n",
       " 127: 466,\n",
       " 128: 469,\n",
       " 129: 471,\n",
       " 130: 472,\n",
       " 131: 473,\n",
       " 132: 478,\n",
       " 133: 479,\n",
       " 134: 480,\n",
       " 135: 481,\n",
       " 136: 489,\n",
       " 137: 494,\n",
       " 138: 498,\n",
       " 139: 504,\n",
       " 140: 505,\n",
       " 141: 509,\n",
       " 142: 513,\n",
       " 143: 515,\n",
       " 144: 522,\n",
       " 145: 526,\n",
       " 146: 531,\n",
       " 147: 535,\n",
       " 148: 539,\n",
       " 149: 540,\n",
       " 150: 543,\n",
       " 151: 548,\n",
       " 152: 554,\n",
       " 153: 562,\n",
       " 154: 574,\n",
       " 155: 576,\n",
       " 156: 578,\n",
       " 157: 582,\n",
       " 158: 586,\n",
       " 159: 588,\n",
       " 160: 590,\n",
       " 161: 591,\n",
       " 162: 595,\n",
       " 163: 601,\n",
       " 164: 607,\n",
       " 165: 608,\n",
       " 166: 611,\n",
       " 167: 613,\n",
       " 168: 620,\n",
       " 169: 621,\n",
       " 170: 625,\n",
       " 171: 626,\n",
       " 172: 628,\n",
       " 173: 633,\n",
       " 174: 637,\n",
       " 175: 643,\n",
       " 176: 646,\n",
       " 177: 647,\n",
       " 178: 648,\n",
       " 179: 651,\n",
       " 180: 654,\n",
       " 181: 655,\n",
       " 182: 656,\n",
       " 183: 660,\n",
       " 184: 661,\n",
       " 185: 665,\n",
       " 186: 666,\n",
       " 187: 668,\n",
       " 188: 670,\n",
       " 189: 671,\n",
       " 190: 673,\n",
       " 191: 674,\n",
       " 192: 677,\n",
       " 193: 678,\n",
       " 194: 679,\n",
       " 195: 680,\n",
       " 196: 681,\n",
       " 197: 685,\n",
       " 198: 690,\n",
       " 199: 692,\n",
       " 200: 698,\n",
       " 201: 700,\n",
       " 202: 706,\n",
       " 203: 708,\n",
       " 204: 709,\n",
       " 205: 715,\n",
       " 206: 716,\n",
       " 207: 717,\n",
       " 208: 719,\n",
       " 209: 728,\n",
       " 210: 729,\n",
       " 211: 733,\n",
       " 212: 735,\n",
       " 213: 744,\n",
       " 214: 753,\n",
       " 215: 758,\n",
       " 216: 759,\n",
       " 217: 760,\n",
       " 218: 766,\n",
       " 219: 770,\n",
       " 220: 773,\n",
       " 221: 774,\n",
       " 222: 776,\n",
       " 223: 782,\n",
       " 224: 790,\n",
       " 225: 797,\n",
       " 226: 801,\n",
       " 227: 805,\n",
       " 228: 808,\n",
       " 229: 813,\n",
       " 230: 817,\n",
       " 231: 818,\n",
       " 232: 820,\n",
       " 233: 822,\n",
       " 234: 825,\n",
       " 235: 826,\n",
       " 236: 827,\n",
       " 237: 830,\n",
       " 238: 833,\n",
       " 239: 838,\n",
       " 240: 840,\n",
       " 241: 850,\n",
       " 242: 851,\n",
       " 243: 852,\n",
       " 244: 853,\n",
       " 245: 860,\n",
       " 246: 862,\n",
       " 247: 864,\n",
       " 248: 867,\n",
       " 249: 870,\n",
       " 250: 872,\n",
       " 251: 873,\n",
       " 252: 875,\n",
       " 253: 876,\n",
       " 254: 877,\n",
       " 255: 881,\n",
       " 256: 883,\n",
       " 257: 890,\n",
       " 258: 898,\n",
       " 259: 904,\n",
       " 260: 905,\n",
       " 261: 908,\n",
       " 262: 911,\n",
       " 263: 913,\n",
       " 264: 914,\n",
       " 265: 915,\n",
       " 266: 916,\n",
       " 267: 918,\n",
       " 268: 919,\n",
       " 269: 923,\n",
       " 270: 929,\n",
       " 271: 932,\n",
       " 272: 939,\n",
       " 273: 946,\n",
       " 274: 948,\n",
       " 275: 955,\n",
       " 276: 965,\n",
       " 277: 973,\n",
       " 278: 981,\n",
       " 279: 982,\n",
       " 280: 987,\n",
       " 281: 988,\n",
       " 282: 990,\n",
       " 283: 998,\n",
       " 284: 999,\n",
       " 285: 1000,\n",
       " 286: 1008,\n",
       " 287: 1017,\n",
       " 288: 1018,\n",
       " 289: 1020,\n",
       " 290: 1023,\n",
       " 291: 1026,\n",
       " 292: 1029,\n",
       " 293: 1032,\n",
       " 294: 1035,\n",
       " 295: 1039,\n",
       " 296: 1042,\n",
       " 297: 1045,\n",
       " 298: 1047,\n",
       " 299: 1049,\n",
       " 300: 1052,\n",
       " 301: 1060,\n",
       " 302: 1062,\n",
       " 303: 1066,\n",
       " 304: 1067,\n",
       " 305: 1068,\n",
       " 306: 1070,\n",
       " 307: 1071,\n",
       " 308: 1081,\n",
       " 309: 1083,\n",
       " 310: 1086,\n",
       " 311: 1087,\n",
       " 312: 1090,\n",
       " 313: 1091,\n",
       " 314: 1100,\n",
       " 315: 1108,\n",
       " 316: 1110,\n",
       " 317: 1113,\n",
       " 318: 1117,\n",
       " 319: 1119,\n",
       " 320: 1126,\n",
       " 321: 1128,\n",
       " 322: 1131,\n",
       " 323: 1132,\n",
       " 324: 1137,\n",
       " 325: 1138,\n",
       " 326: 1139,\n",
       " 327: 1140,\n",
       " 328: 1143,\n",
       " 329: 1144,\n",
       " 330: 1147,\n",
       " 331: 1150,\n",
       " 332: 1151,\n",
       " 333: 1152,\n",
       " 334: 1153,\n",
       " 335: 1166,\n",
       " 336: 1167,\n",
       " 337: 1169,\n",
       " 338: 1171,\n",
       " 339: 1175,\n",
       " 340: 1180,\n",
       " 341: 1181,\n",
       " 342: 1186,\n",
       " 343: 1202,\n",
       " 344: 1203,\n",
       " 345: 1208,\n",
       " 346: 1211,\n",
       " 347: 1216,\n",
       " 348: 1221,\n",
       " 349: 1222,\n",
       " 350: 1225,\n",
       " 351: 1229,\n",
       " 352: 1236,\n",
       " 353: 1241,\n",
       " 354: 1242,\n",
       " 355: 1243,\n",
       " 356: 1245,\n",
       " 357: 1259,\n",
       " 358: 1262,\n",
       " 359: 1268,\n",
       " 360: 1269,\n",
       " 361: 1276,\n",
       " 362: 1282,\n",
       " 363: 1286,\n",
       " 364: 1290,\n",
       " 365: 1294,\n",
       " 366: 1295,\n",
       " 367: 1296,\n",
       " 368: 1298,\n",
       " 369: 1300,\n",
       " 370: 1303,\n",
       " 371: 1305,\n",
       " 372: 1309,\n",
       " 373: 1314,\n",
       " 374: 1324,\n",
       " 375: 1325,\n",
       " 376: 1335,\n",
       " 377: 1338,\n",
       " 378: 1349,\n",
       " 379: 1350,\n",
       " 380: 1355,\n",
       " 381: 1362,\n",
       " 382: 1366,\n",
       " 383: 1367,\n",
       " 384: 1371,\n",
       " 385: 1380,\n",
       " 386: 1382,\n",
       " 387: 1384,\n",
       " 388: 1385,\n",
       " 389: 1387,\n",
       " 390: 1390,\n",
       " 391: 1392,\n",
       " 392: 1395,\n",
       " 393: 1398,\n",
       " 394: 1399,\n",
       " 395: 1403,\n",
       " 396: 1405,\n",
       " 397: 1414,\n",
       " 398: 1417,\n",
       " 399: 1424,\n",
       " 400: 1425,\n",
       " 401: 1436,\n",
       " 402: 1440,\n",
       " 403: 1441,\n",
       " 404: 1442,\n",
       " 405: 1445,\n",
       " 406: 1452,\n",
       " 407: 1458,\n",
       " 408: 1464,\n",
       " 409: 1465,\n",
       " 410: 1466,\n",
       " 411: 1467,\n",
       " 412: 1470,\n",
       " 413: 1476,\n",
       " 414: 1477,\n",
       " 415: 1481,\n",
       " 416: 1486,\n",
       " 417: 1491,\n",
       " 418: 1495,\n",
       " 419: 1496,\n",
       " 420: 1498,\n",
       " 421: 1502,\n",
       " 422: 1512,\n",
       " 423: 1513,\n",
       " 424: 1515,\n",
       " 425: 1521,\n",
       " 426: 1523,\n",
       " 427: 1525,\n",
       " 428: 1528,\n",
       " 429: 1529,\n",
       " 430: 1532,\n",
       " 431: 1534,\n",
       " 432: 1541,\n",
       " 433: 1542,\n",
       " 434: 1543,\n",
       " 435: 1548,\n",
       " 436: 1549,\n",
       " 437: 1550,\n",
       " 438: 1562,\n",
       " 439: 1564,\n",
       " 440: 1573,\n",
       " 441: 1580,\n",
       " 442: 1581,\n",
       " 443: 1588,\n",
       " 444: 1589,\n",
       " 445: 1594,\n",
       " 446: 1596,\n",
       " 447: 1599,\n",
       " 448: 1601,\n",
       " 449: 1607,\n",
       " 450: 1611,\n",
       " 451: 1613,\n",
       " 452: 1617,\n",
       " 453: 1624,\n",
       " 454: 1629,\n",
       " 455: 1631,\n",
       " 456: 1637,\n",
       " 457: 1641,\n",
       " 458: 1645,\n",
       " 459: 1650,\n",
       " 460: 1652,\n",
       " 461: 1654,\n",
       " 462: 1656,\n",
       " 463: 1657,\n",
       " 464: 1659,\n",
       " 465: 1661,\n",
       " 466: 1662,\n",
       " 467: 1672,\n",
       " 468: 1679,\n",
       " 469: 1686,\n",
       " 470: 1696,\n",
       " 471: 1701,\n",
       " 472: 1705,\n",
       " 473: 1707,\n",
       " 474: 1717,\n",
       " 475: 1720,\n",
       " 476: 1726,\n",
       " 477: 1728,\n",
       " 478: 1733,\n",
       " 479: 1734,\n",
       " 480: 1735,\n",
       " 481: 1738,\n",
       " 482: 1745,\n",
       " 483: 1749,\n",
       " 484: 1752,\n",
       " 485: 1754,\n",
       " 486: 1755,\n",
       " 487: 1756,\n",
       " 488: 1764,\n",
       " 489: 1769,\n",
       " 490: 1772,\n",
       " 491: 1775,\n",
       " 492: 1777,\n",
       " 493: 1779,\n",
       " 494: 1780,\n",
       " 495: 1781,\n",
       " 496: 1784,\n",
       " 497: 1785,\n",
       " 498: 1786,\n",
       " 499: 1790,\n",
       " 500: 1794,\n",
       " 501: 1801,\n",
       " 502: 1803,\n",
       " 503: 1808,\n",
       " 504: 1809,\n",
       " 505: 1814,\n",
       " 506: 1815,\n",
       " 507: 1819,\n",
       " 508: 1823,\n",
       " 509: 1824,\n",
       " 510: 1827,\n",
       " 511: 1828,\n",
       " 512: 1829,\n",
       " 513: 1830,\n",
       " 514: 1835,\n",
       " 515: 1840,\n",
       " 516: 1842,\n",
       " 517: 1845,\n",
       " 518: 1846,\n",
       " 519: 1848,\n",
       " 520: 1849,\n",
       " 521: 1853,\n",
       " 522: 1854,\n",
       " 523: 1856,\n",
       " 524: 1858,\n",
       " 525: 1861,\n",
       " 526: 1863,\n",
       " 527: 1864,\n",
       " 528: 1865,\n",
       " 529: 1873,\n",
       " 530: 1874,\n",
       " 531: 1878,\n",
       " 532: 1879,\n",
       " 533: 1893,\n",
       " 534: 1894,\n",
       " 535: 1895,\n",
       " 536: 1897,\n",
       " 537: 1898,\n",
       " 538: 1900,\n",
       " 539: 1903,\n",
       " 540: 1912,\n",
       " 541: 1913,\n",
       " 542: 1914,\n",
       " 543: 1916,\n",
       " 544: 1917,\n",
       " 545: 1920,\n",
       " 546: 1921,\n",
       " 547: 1922,\n",
       " 548: 1923,\n",
       " 549: 1924,\n",
       " 550: 1927,\n",
       " 551: 1934,\n",
       " 552: 1940,\n",
       " 553: 1941,\n",
       " 554: 1950,\n",
       " 555: 1960,\n",
       " 556: 1965,\n",
       " 557: 1967,\n",
       " 558: 1972,\n",
       " 559: 1975,\n",
       " 560: 1981,\n",
       " 561: 1984,\n",
       " 562: 1985,\n",
       " 563: 1986,\n",
       " 564: 1995,\n",
       " 565: 2007,\n",
       " 566: 2008,\n",
       " 567: 2009,\n",
       " 568: 2013,\n",
       " 569: 2014,\n",
       " 570: 2015,\n",
       " 571: 2025,\n",
       " 572: 2026,\n",
       " 573: 2029,\n",
       " 574: 2034,\n",
       " 575: 2036,\n",
       " 576: 2041,\n",
       " 577: 2047,\n",
       " 578: 2049,\n",
       " 579: 2050,\n",
       " 580: 2051,\n",
       " 581: 2064,\n",
       " 582: 2065,\n",
       " 583: 2066,\n",
       " 584: 2071,\n",
       " 585: 2077,\n",
       " 586: 2080,\n",
       " 587: 2082,\n",
       " 588: 2087,\n",
       " 589: 2090,\n",
       " 590: 2106,\n",
       " 591: 2113,\n",
       " 592: 2114,\n",
       " 593: 2120,\n",
       " 594: 2129,\n",
       " 595: 2130,\n",
       " 596: 2131,\n",
       " 597: 2144,\n",
       " 598: 2150,\n",
       " 599: 2162,\n",
       " 600: 2163,\n",
       " 601: 2165,\n",
       " 602: 2168,\n",
       " 603: 2169,\n",
       " 604: 2177,\n",
       " 605: 2182,\n",
       " 606: 2184,\n",
       " 607: 2185,\n",
       " 608: 2192,\n",
       " 609: 2193,\n",
       " 610: 2198,\n",
       " 611: 2202,\n",
       " 612: 2204,\n",
       " 613: 2206,\n",
       " 614: 2208,\n",
       " 615: 2213,\n",
       " 616: 2218,\n",
       " 617: 2219,\n",
       " 618: 2224,\n",
       " 619: 2226,\n",
       " 620: 2234,\n",
       " 621: 2235,\n",
       " 622: 2242,\n",
       " 623: 2243,\n",
       " 624: 2250,\n",
       " 625: 2253,\n",
       " 626: 2254,\n",
       " 627: 2255,\n",
       " 628: 2256,\n",
       " 629: 2259,\n",
       " 630: 2263,\n",
       " 631: 2270,\n",
       " 632: 2272,\n",
       " 633: 2274,\n",
       " 634: 2280,\n",
       " 635: 2281,\n",
       " 636: 2296,\n",
       " 637: 2301,\n",
       " 638: 2302,\n",
       " 639: 2303,\n",
       " 640: 2305,\n",
       " 641: 2308,\n",
       " 642: 2309,\n",
       " 643: 2315,\n",
       " 644: 2316,\n",
       " 645: 2319,\n",
       " 646: 2321,\n",
       " 647: 2323,\n",
       " 648: 2324,\n",
       " 649: 2333,\n",
       " 650: 2335,\n",
       " 651: 2342,\n",
       " 652: 2343,\n",
       " 653: 2351,\n",
       " 654: 2352,\n",
       " 655: 2353,\n",
       " 656: 2355,\n",
       " 657: 2357,\n",
       " 658: 2369,\n",
       " 659: 2372,\n",
       " 660: 2373,\n",
       " 661: 2375,\n",
       " 662: 2378,\n",
       " 663: 2379,\n",
       " 664: 2385,\n",
       " 665: 2388,\n",
       " 666: 2395,\n",
       " 667: 2399,\n",
       " 668: 2400,\n",
       " 669: 2403,\n",
       " 670: 2407,\n",
       " 671: 2418,\n",
       " 672: 2425,\n",
       " 673: 2433,\n",
       " 674: 2437,\n",
       " 675: 2438,\n",
       " 676: 2441,\n",
       " 677: 2444,\n",
       " 678: 2446,\n",
       " 679: 2450,\n",
       " 680: 2452,\n",
       " 681: 2455,\n",
       " 682: 2458,\n",
       " 683: 2460,\n",
       " 684: 2461,\n",
       " 685: 2462,\n",
       " 686: 2472,\n",
       " 687: 2473,\n",
       " 688: 2474,\n",
       " 689: 2480,\n",
       " 690: 2483,\n",
       " 691: 2487,\n",
       " 692: 2489,\n",
       " 693: 2491,\n",
       " 694: 2503,\n",
       " 695: 2509,\n",
       " 696: 2511,\n",
       " 697: 2512,\n",
       " 698: 2514,\n",
       " 699: 2515,\n",
       " 700: 2518,\n",
       " 701: 2519,\n",
       " 702: 2522,\n",
       " 703: 2523,\n",
       " 704: 2526,\n",
       " 705: 2528,\n",
       " 706: 2529,\n",
       " 707: 2536,\n",
       " 708: 2540,\n",
       " 709: 2541,\n",
       " 710: 2543,\n",
       " 711: 2552,\n",
       " 712: 2554,\n",
       " 713: 2556,\n",
       " 714: 2557,\n",
       " 715: 2561,\n",
       " 716: 2562,\n",
       " 717: 2565,\n",
       " 718: 2569,\n",
       " 719: 2570,\n",
       " 720: 2575,\n",
       " 721: 2579,\n",
       " 722: 2585,\n",
       " 723: 2592,\n",
       " 724: 2594,\n",
       " 725: 2598,\n",
       " 726: 2600,\n",
       " 727: 2604,\n",
       " 728: 2606,\n",
       " 729: 2611,\n",
       " 730: 2612,\n",
       " 731: 2613,\n",
       " 732: 2618,\n",
       " 733: 2620,\n",
       " 734: 2624,\n",
       " 735: 2631,\n",
       " 736: 2632,\n",
       " 737: 2634,\n",
       " 738: 2637,\n",
       " 739: 2645,\n",
       " 740: 2650,\n",
       " 741: 2653,\n",
       " 742: 2656,\n",
       " 743: 2660,\n",
       " 744: 2661,\n",
       " 745: 2664,\n",
       " 746: 2672,\n",
       " 747: 2674,\n",
       " 748: 2677,\n",
       " 749: 2680,\n",
       " 750: 2684,\n",
       " 751: 2686,\n",
       " 752: 2692,\n",
       " 753: 2694,\n",
       " 754: 2701,\n",
       " 755: 2702,\n",
       " 756: 2704,\n",
       " 757: 2709,\n",
       " 758: 2715,\n",
       " 759: 2716,\n",
       " 760: 2729,\n",
       " 761: 2737,\n",
       " 762: 2738,\n",
       " 763: 2740,\n",
       " 764: 2741,\n",
       " 765: 2748,\n",
       " 766: 2753,\n",
       " 767: 2754,\n",
       " 768: 2755,\n",
       " 769: 2760,\n",
       " 770: 2765,\n",
       " 771: 2766,\n",
       " 772: 2767,\n",
       " 773: 2773,\n",
       " 774: 2776,\n",
       " 775: 2781,\n",
       " 776: 2782,\n",
       " 777: 2785,\n",
       " 778: 2787,\n",
       " 779: 2788,\n",
       " 780: 2792,\n",
       " 781: 2795,\n",
       " 782: 2802,\n",
       " 783: 2804,\n",
       " 784: 2805,\n",
       " 785: 2811,\n",
       " 786: 2813,\n",
       " 787: 2816,\n",
       " 788: 2818,\n",
       " 789: 2819,\n",
       " 790: 2822,\n",
       " 791: 2829,\n",
       " 792: 2832,\n",
       " 793: 2834,\n",
       " 794: 2835,\n",
       " 795: 2836,\n",
       " 796: 2839,\n",
       " 797: 2848,\n",
       " 798: 2850,\n",
       " 799: 2852,\n",
       " 800: 2855,\n",
       " 801: 2857,\n",
       " 802: 2859,\n",
       " 803: 2860,\n",
       " 804: 2866,\n",
       " 805: 2868,\n",
       " 806: 2869,\n",
       " 807: 2871,\n",
       " 808: 2875,\n",
       " 809: 2877,\n",
       " 810: 2880,\n",
       " 811: 2881,\n",
       " 812: 2882,\n",
       " 813: 2883,\n",
       " 814: 2887,\n",
       " 815: 2891,\n",
       " 816: 2894,\n",
       " 817: 2904,\n",
       " 818: 2905,\n",
       " 819: 2909,\n",
       " 820: 2912,\n",
       " 821: 2921,\n",
       " 822: 2922,\n",
       " 823: 2924,\n",
       " 824: 2930,\n",
       " 825: 2934,\n",
       " 826: 2942,\n",
       " 827: 2947,\n",
       " 828: 2952,\n",
       " 829: 2959,\n",
       " 830: 2960,\n",
       " 831: 2962,\n",
       " 832: 2964,\n",
       " 833: 2965,\n",
       " 834: 2968,\n",
       " 835: 2970,\n",
       " 836: 2971,\n",
       " 837: 2976,\n",
       " 838: 2979,\n",
       " 839: 2980,\n",
       " 840: 2982,\n",
       " 841: 2984,\n",
       " 842: 2988,\n",
       " 843: 2989,\n",
       " 844: 2991,\n",
       " 845: 2992,\n",
       " 846: 2993,\n",
       " 847: 2994,\n",
       " 848: 2995,\n",
       " 849: 2997,\n",
       " 850: 2998,\n",
       " 851: 2999,\n",
       " 852: 3011,\n",
       " 853: 3012,\n",
       " 854: 3013,\n",
       " 855: 3015,\n",
       " 856: 3017,\n",
       " 857: 3022,\n",
       " 858: 3024,\n",
       " 859: 3026,\n",
       " 860: 3027,\n",
       " 861: 3028,\n",
       " 862: 3029,\n",
       " 863: 3030,\n",
       " 864: 3034,\n",
       " 865: 3042,\n",
       " 866: 3044,\n",
       " 867: 3045,\n",
       " 868: 3046,\n",
       " 869: 3050,\n",
       " 870: 3052,\n",
       " 871: 3054,\n",
       " 872: 3056,\n",
       " 873: 3057,\n",
       " 874: 3066,\n",
       " 875: 3068,\n",
       " 876: 3069,\n",
       " 877: 3070,\n",
       " 878: 3073,\n",
       " 879: 3075,\n",
       " 880: 3083,\n",
       " 881: 3089,\n",
       " 882: 3095,\n",
       " 883: 3096,\n",
       " 884: 3100,\n",
       " 885: 3101,\n",
       " 886: 3104,\n",
       " 887: 3107,\n",
       " 888: 3108,\n",
       " 889: 3110,\n",
       " 890: 3113,\n",
       " 891: 3115,\n",
       " 892: 3117,\n",
       " 893: 3121,\n",
       " 894: 3122,\n",
       " 895: 3123,\n",
       " 896: 3131,\n",
       " 897: 3133,\n",
       " 898: 3134,\n",
       " 899: 3136,\n",
       " 900: 3139,\n",
       " 901: 3140,\n",
       " 902: 3142,\n",
       " 903: 3143,\n",
       " 904: 3144,\n",
       " 905: 3145,\n",
       " 906: 3146,\n",
       " 907: 3150,\n",
       " 908: 3152,\n",
       " 909: 3155,\n",
       " 910: 3156,\n",
       " 911: 3157,\n",
       " 912: 3158,\n",
       " 913: 3161,\n",
       " 914: 3166,\n",
       " 915: 3176,\n",
       " 916: 3179,\n",
       " 917: 3191,\n",
       " 918: 3192,\n",
       " 919: 3195,\n",
       " 920: 3197,\n",
       " 921: 3199,\n",
       " 922: 3201,\n",
       " 923: 3204,\n",
       " 924: 3206,\n",
       " 925: 3210,\n",
       " 926: 3232,\n",
       " 927: 3243,\n",
       " 928: 3247,\n",
       " 929: 3250,\n",
       " 930: 3251,\n",
       " 931: 3253,\n",
       " 932: 3256,\n",
       " 933: 3270,\n",
       " 934: 3274,\n",
       " 935: 3275,\n",
       " 936: 3282,\n",
       " 937: 3284,\n",
       " 938: 3285,\n",
       " 939: 3287,\n",
       " 940: 3289,\n",
       " 941: 3291,\n",
       " 942: 3292,\n",
       " 943: 3294,\n",
       " 944: 3295,\n",
       " 945: 3298,\n",
       " 946: 3309,\n",
       " 947: 3314,\n",
       " 948: 3321,\n",
       " 949: 3323,\n",
       " 950: 3324,\n",
       " 951: 3328,\n",
       " 952: 3330,\n",
       " 953: 3336,\n",
       " 954: 3342,\n",
       " 955: 3344,\n",
       " 956: 3345,\n",
       " 957: 3348,\n",
       " 958: 3357,\n",
       " 959: 3362,\n",
       " 960: 3365,\n",
       " 961: 3367,\n",
       " 962: 3369,\n",
       " 963: 3371,\n",
       " 964: 3372,\n",
       " 965: 3380,\n",
       " 966: 3381,\n",
       " 967: 3386,\n",
       " 968: 3389,\n",
       " 969: 3393,\n",
       " 970: 3395,\n",
       " 971: 3399,\n",
       " 972: 3404,\n",
       " 973: 3408,\n",
       " 974: 3409,\n",
       " 975: 3410,\n",
       " 976: 3417,\n",
       " 977: 3420,\n",
       " 978: 3428,\n",
       " 979: 3429,\n",
       " 980: 3437,\n",
       " 981: 3441,\n",
       " 982: 3442,\n",
       " 983: 3449,\n",
       " 984: 3457,\n",
       " 985: 3458,\n",
       " 986: 3459,\n",
       " 987: 3464,\n",
       " 988: 3467,\n",
       " 989: 3469,\n",
       " 990: 3470,\n",
       " 991: 3476,\n",
       " 992: 3480,\n",
       " 993: 3482,\n",
       " 994: 3489,\n",
       " 995: 3490,\n",
       " 996: 3492,\n",
       " 997: 3493,\n",
       " 998: 3495,\n",
       " 999: 3497,\n",
       " ...}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx2realidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim_matrix = cosine_similarity(model.type_means(torch.tensor(types)).detach().numpy(), \n",
    "                                   model.type_means(torch.tensor(types)).detach().numpy())\n",
    "def n_closest_words(word, cos_sim_matrix, n):\n",
    "    word_index = test_realidx2idx.get(word2idx.get(word))\n",
    "    print(\"word_index is \" + str(word_index))\n",
    "    close_words_indices = np.argsort(cos_sim_matrix[word_index])[-n:]\n",
    "#     print(\"close_words_indices.shape\" + str(close_words_indices.shape))\n",
    "    return [idx2word.get(test_idx2realidx.get(j)) for j in close_words_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index is 917\n",
      "close_words_indices.shape(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['disappointment',\n",
       " 'alongside',\n",
       " 'opportunity',\n",
       " 'safety',\n",
       " None,\n",
       " 'significantly',\n",
       " 'right',\n",
       " 'content',\n",
       " None,\n",
       " 'ivy',\n",
       " 'norwegian',\n",
       " None,\n",
       " 'overwhelmingly',\n",
       " 'checked',\n",
       " 'junior',\n",
       " 'accept',\n",
       " 'moral',\n",
       " 'mice',\n",
       " 'its',\n",
       " 'pressure']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_closest_words(\"pressure\", cos_sim_matrix, 20) # assault, financial, mental, income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96650124], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.type_logvars(torch.tensor(word2idx.get(\"thing\"))).detach().exp().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.type_logvars(torch.tensor(types)).detach().exp().numpy().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'voting'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word.get(test_idx2realidx.get(1122))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.7332592e-02,  5.2747063e-02, -5.1449113e-02, -4.7027846e-03,\n",
       "        5.4603245e-02, -1.2933372e-01,  1.5721838e-01,  7.5663537e-02,\n",
       "       -6.2025711e-02,  1.7656371e-02,  2.5907028e-01,  3.4677573e-02,\n",
       "       -8.4819712e-02, -2.6605096e-01,  1.3948311e-01,  8.4106237e-02,\n",
       "       -2.1419908e-04,  1.3475612e-01,  2.2660490e-02,  9.7617179e-02,\n",
       "       -1.5277818e-01,  1.2325918e-02,  1.0303870e-01, -3.8719811e-02,\n",
       "       -1.9681072e-01, -3.2387976e-02,  1.6129054e-02, -5.6416623e-02,\n",
       "        1.3454187e-01,  2.9165758e-02], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.syn0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.7332592e-02,  5.2747063e-02, -5.1449113e-02, -4.7027846e-03,\n",
       "        5.4603245e-02, -1.2933372e-01,  1.5721838e-01,  7.5663537e-02,\n",
       "       -6.2025711e-02,  1.7656371e-02,  2.5907028e-01,  3.4677573e-02,\n",
       "       -8.4819712e-02, -2.6605096e-01,  1.3948311e-01,  8.4106237e-02,\n",
       "       -2.1419908e-04,  1.3475612e-01,  2.2660490e-02,  9.7617179e-02,\n",
       "       -1.5277818e-01,  1.2325918e-02,  1.0303870e-01, -3.8719811e-02,\n",
       "       -1.9681072e-01, -3.2387976e-02,  1.6129054e-02, -5.6416623e-02,\n",
       "        1.3454187e-01,  2.9165758e-02], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.get_vector(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wv.index2word\n",
    "w2v_word2idx = {w: idx for (idx , w) in enumerate(w2v.wv.index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:2: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_tokenized_corpus = tools.flatten(tokenized_corpus)\n",
    "len(np.unique(flattened_tokenized_corpus)) == w2v.syn0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "w2v_cos_sim_matrix = cosine_similarity(w2v.wv.syn0, w2v.wv.syn0)\n",
    "def w2v_n_closest_words(word, cos_sim_matrix, n):\n",
    "    word_index = w2v_word2idx.get(word)\n",
    "    print(\"word_index is \" + str(word_index))\n",
    "    close_words_indices = np.argsort(cos_sim_matrix[word_index])[-n:]\n",
    "#     print(\"close_words_indices.shape\" + str(close_words_indices.shape))\n",
    "    return [w2v.wv.index2word[j] for j in close_words_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index is 87\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rather',\n",
       " 'students',\n",
       " 'time',\n",
       " 'yet',\n",
       " 'society',\n",
       " 'restrained',\n",
       " 'hamas',\n",
       " 'president',\n",
       " 'wanted',\n",
       " 'peer',\n",
       " 'operation',\n",
       " 'animals',\n",
       " 'campus',\n",
       " 'set',\n",
       " 'sexual',\n",
       " 'providing',\n",
       " 'engagement',\n",
       " 'one',\n",
       " 'health',\n",
       " 'mental']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_n_closest_words(\"mental\", w2v_cos_sim_matrix, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:math689env]",
   "language": "python",
   "name": "conda-env-math689env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
