{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import bsg, tools\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "princeton_data = pd.read_csv(\"articles_1999.csv\", delimiter=\"\\|\\~\\|\", header=None)\n",
    "princeton_data.columns = [\"ID\", \"headline\", \"date\", \"type\", \"author\", \"author_title\", \"article\", \"author_bio\"]\n",
    "princeton_data = princeton_data[princeton_data[\"article\"].notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prince_data = list(princeton_data.loc[0:25,\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prince_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stuff ###\n",
    "\n",
    "window = 2\n",
    "t = np.power(10.0,-4.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, tokenized_corpus, word2idx, idx2word = tools.tokenize_corpus(prince_data)\n",
    "\n",
    "indexed_corpus = tools.index_tokenized_corpus(tokenized_corpus, word2idx)\n",
    "\n",
    "flattened_indexed_corpus = tools.flatten(indexed_corpus)\n",
    "unigram_subsampling = tools.make_unigram_dict(flattened_indexed_corpus)\n",
    "\n",
    "subsampled_indexed_corpus = tools.subsample_corpus(indexed_corpus, unigram_subsampling, t)\n",
    "\n",
    "sum([len(doc) for doc in subsampled_indexed_corpus])\n",
    "\n",
    "len(flattened_indexed_corpus)\n",
    "\n",
    "corpus_center_words, corpus_context_words = tools.get_corpus_centers_contexts(subsampled_indexed_corpus, window)\n",
    "\n",
    "unigram = tools.make_unigram_dict(corpus_center_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## w2v ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_prince = list(princeton_data.loc[0:princeton_data.shape[0],6])\n",
    "# vocabulary, tokenized_corpus, word2idx, idx2word = tools.tokenize_corpus(princeton_data[\"article\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329677, 607650)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### word2vec ###\n",
    "\n",
    "w2v = Word2Vec(sample = t, sg=1, negative=1, size=100, window=2, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "\n",
    "w2v.build_vocab(tokenized_corpus)  # prepare the model vocabulary\n",
    "w2v.train(tokenized_corpus, total_examples=w2v.corpus_count, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"barbara\" in w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('health', 0.5791363716125488),\n",
       " ('the', 0.5690140128135681),\n",
       " ('experience', 0.5158798694610596),\n",
       " ('not', 0.5035669803619385),\n",
       " ('for', 0.5034538507461548),\n",
       " ('with', 0.5011468529701233),\n",
       " ('always', 0.47424519062042236),\n",
       " ('and', 0.47265416383743286),\n",
       " ('campus', 0.4568369686603546),\n",
       " ('like', 0.45284149050712585)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(\"mental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get corpus: 20 news groups\n",
    "\n",
    "# newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# window = 5\n",
    "\n",
    "# vocabulary, tokenized_corpus, word2idx, idx2word = tools.tokenize_corpus(newsgroups_train.data)\n",
    "\n",
    "# indexed_corpus = tools.index_tokenized_corpus(tokenized_corpus, word2idx)\n",
    "\n",
    "# corpus_center_words, corpus_context_words = tools.get_corpus_centers_contexts(indexed_corpus, window)\n",
    "\n",
    "# unigram = tools.make_unigram_dict(corpus_center_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\"vocab_size\" : len(vocabulary), \"window\" : window, \n",
    "             \"batch_size\" : 200, \"optimizer\" : 80, \"learning_rate\" : 0.0005, \n",
    "             \"momentum\" : 0.99, \"num_epoch\" : 50, \"init_mult\" : 1, \n",
    "             \"variance\" : 0.995, \"start\" : True, \"nogpu\" : True, \n",
    "             \"embedding_dim\" : 300, \"freeze\" : False}\n",
    "\n",
    "args = SimpleNamespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristyn/Desktop/Python/bsg_pytorch/bsg.py:111: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  loss_epoch += loss.data[0]    # add loss to loss_epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=144670.390625\n",
      "Epoch 5, loss=78010.9765625\n",
      "Epoch 10, loss=55961.828125\n",
      "Epoch 15, loss=42342.171875\n",
      "Epoch 20, loss=32400.54296875\n",
      "Epoch 25, loss=25242.056640625\n",
      "Epoch 30, loss=20759.263671875\n",
      "Epoch 35, loss=16871.8046875\n",
      "Epoch 40, loss=14552.9599609375\n",
      "Epoch 45, loss=12564.931640625\n"
     ]
    }
   ],
   "source": [
    "model = bsg.BSG(args.window, unigram, args.vocab_size, input_dim = 25)\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "model = bsg.train(model, args, optimizer, corpus_center_words, corpus_context_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"bsg_prince_50e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"bsg_prince_50e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word(corpus_center_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "types, counts = np.unique(corpus_center_words.tolist(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx2realidx = {idx: realidx for (idx , realidx) in enumerate(types)}\n",
    "test_realidx2idx = {realidx: idx for (idx , realidx) in enumerate(types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim_matrix = cosine_similarity(model.type_means(torch.tensor(types)).detach().numpy(), \n",
    "                                   model.type_means(torch.tensor(types)).detach().numpy())\n",
    "def n_closest_words(word, cos_sim_matrix, n):\n",
    "    word_index = test_realidx2idx.get(word2idx.get(word))\n",
    "    print(\"word_index is \" + str(word_index))\n",
    "    close_words_indices = np.argsort(cos_sim_matrix[word_index])[-n:]\n",
    "    print(\"close_words_indices.shape\" + str(close_words_indices.shape))\n",
    "    return [idx2word.get(test_idx2realidx.get(j)) for j in close_words_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index is 784\n",
      "close_words_indices.shape(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['plans',\n",
       " 'swap',\n",
       " 'reform',\n",
       " 'says',\n",
       " 'application',\n",
       " 'entire',\n",
       " 'interest',\n",
       " 'idea',\n",
       " 'objective',\n",
       " 'address',\n",
       " 'muhedini',\n",
       " 'four',\n",
       " 'outcomes',\n",
       " 'money',\n",
       " 'seemed',\n",
       " 'organizer',\n",
       " 'campaign',\n",
       " 'half',\n",
       " 'shawshank',\n",
       " 'fraternity']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_closest_words(\"fraternity\", cos_sim_matrix, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1220"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(test_idx2realidx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3268, 100])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.type_means.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:math689env]",
   "language": "python",
   "name": "conda-env-math689env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
